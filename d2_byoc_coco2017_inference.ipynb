{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hosting Detectron2 model on Sagemaker Inference endpoint\n",
    "\n",
    "In this notebook we'll package previously trained model into PyTorch Serving container and deploy it on Sagemaker. First, let's review serving container. There are two key difference comparing to training container:\n",
    "- we are using different base container provided by Sagemaker;\n",
    "- we need to start Web server (refer to ENTRYPOINT command)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling Serving Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pygmentize -l docker Dockerfile.serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in case of training image, we'll need to build and push container to AWS ECR. Before this, we'll need to loging to shared Sagemaker ECR and your local ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n"
     ]
    }
   ],
   "source": [
    "# loging to Sagemaker ECR with Deep Learning Containers\n",
    "!aws ecr get-login-password --region us-east-2 | docker login --username AWS --password-stdin 763104351884.dkr.ecr.us-east-2.amazonaws.com\n",
    "# loging to your private ECR\n",
    "!aws ecr get-login-password --region us-east-2 | docker login --username AWS --password-stdin 553020858742.dkr.ecr.us-east-2.amazonaws.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's build and push container using follow command. Note, that here we supply non-default Dockerfile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./build_and_push.sh d2-sm-coco-serving latest Dockerfile.serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing test data\n",
    "\n",
    "We'll be using coco2017 validation dataset. To simplify working with it, let's install locally Pycoco package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U scikit-image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's download Coco2017 validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../datasets/coco/\" # folder where data will be saved\n",
    "dataset  = \"val2017\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p {data_dir}{dataset}\n",
    "! wget http://images.cocodataset.org/zips/val2017.zip -P {data_dir}\n",
    "! unzip {data_dir}/val2017.zip -d {data_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip -P {data_dir}\n",
    "! unzip {data_dir}/annotations_trainval2017.zip -d {data_dir}{dataset}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a random image ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "\n",
    "annFile='{}{}/annotations/instances_{}.json'.format(data_dir,dataset, dataset)\n",
    "coco=COCO(annFile)\n",
    "\n",
    "# get all images containing given categories, select one at random\n",
    "catIds = coco.getCatIds(catNms=['person','dog']);\n",
    "imgIds = coco.getImgIds(catIds=catIds);\n",
    "imgId = imgIds[np.random.randint(len(imgIds))]\n",
    "image_instance = coco.loadImgs(imgId)[0]\n",
    "image_np = io.imread(image_instance['coco_url'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis('off')\n",
    "plt.imshow(image_np)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing inference script locally\n",
    "\n",
    "Let's first check what inference script we'll deploy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sagemaker-inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize container_serving/predict_coco.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test inference pipeline locally, you can run your `container_serving/predict_coco.py` locally (only code in __main__ guard will be executed). You'll need to have Detectron2 and number other packages locally installed to test it.\n",
    "\n",
    "Make sure that you pass correct --model-dir argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python container_serving/predict_coco.py --image container_serving/coco_sample.jpg --model-dir ../trained_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying Inference Endpoint\n",
    "\n",
    "Below is some initial imports and configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import re\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "import requests\n",
    "import json\n",
    "import pickle\n",
    "import detectron2 \n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from time import gmtime, strftime\n",
    "\n",
    "sess = sagemaker.Session() # can use LocalSession() to run container locally\n",
    "\n",
    "bucket = sess.default_bucket()\n",
    "region = \"us-east-2\"\n",
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "prefix_input = 'detectron2-input'\n",
    "prefix_output = 'detectron2-ouput'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define parameters of your container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Following container will be used for hosting:  553020858742.dkr.ecr.us-east-2.amazonaws.com/d2-sm-coco-serving:latest\n"
     ]
    }
   ],
   "source": [
    "container_serving = \"d2-sm-coco-serving\" # your container name\n",
    "tag = \"latest\" # you can have several version of container available\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/{}:{}'.format(account, region, container_serving, tag)\n",
    "\n",
    "print(\"Following container will be used for hosting: \",image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy endpoint locally\n",
    "\n",
    "As training on COCO2017 can be quite lenghty, we'll deploy our endpoint from model artifacts from already completed training jobs. Please review your training jobs, and find one which succesffuly completed. Then, copy model artifact S3 URI and.  pass it to `model_data` argument below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorchModel, PyTorch, PyTorchPredictor\n",
    "from sagemaker import Model\n",
    "\n",
    "\n",
    "model = PyTorchModel(\n",
    "                     model_data=\"s3://sagemaker-us-east-2-553020858742/detectron2-model/model_R_50_FPN_1x.tar.gz\", # from training job\n",
    "                     role=role,\n",
    "                     entry_point=\"predict_coco.py\", source_dir=\"container_serving\",\n",
    "                     framework_version=\"1.4\", py_version=\"3.6\",\n",
    "                     image=image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = model.deploy(\n",
    "                         instance_type = 'local_gpu',\n",
    "                         initial_instance_count=1,\n",
    "                         endpoint_name=f\"{container_serving}-{tag}\", # define a unqie endpoint name; if ommited, Sagemaker will generate it based on used container\n",
    "                         tags=[{\"Key\":\"image\", \"Value\":f\"{container_serving}:{tag}\"}], \n",
    "                         wait=False\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://172.18.0.2:8080/invocations' # IP address of serving container when deployed locally\n",
    "content_type = 'image/jpeg'\n",
    "accept_type = \"json\" # \"json\" or \"detectron2\" supported\n",
    "headers = {'content-type': content_type, 'accept': accept_type}\n",
    "payload = open('coco_sample.jpg', 'rb')\n",
    "\n",
    "response = requests.post(url, data=payload, headers=headers)\n",
    "\n",
    "if accept_type==\"json\":\n",
    "    predictions = json.loads(response.content)\n",
    "elif accept_type==\"detectron2\":\n",
    "    predictions = pickle.loads(response.content)\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy remote endpoint\n",
    "\n",
    "To process inference data when we are sending it over internet, we need to have two customer ser/deser methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorchModel, PyTorch, PyTorchPredictor\n",
    "from sagemaker.estimator import Estimator, Model\n",
    "\n",
    "remote_model = PyTorchModel(\n",
    "                     model_data=\"s3://sagemaker-us-east-2-553020858742/detectron2-model/model_R_50_FPN_1x.tar.gz\", # from training job\n",
    "                     role=role,\n",
    "                     entry_point=\"predict_coco.py\", source_dir=\"container_serving\",\n",
    "                     framework_version=\"1.4\", py_version=\"3.6\",\n",
    "                     image=image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = f\"{container_serving}-{tag}\"\n",
    "\n",
    "remote_predictor = remote_model.deploy(\n",
    "                         instance_type='ml.p3.16xlarge', \n",
    "                         initial_instance_count=1,\n",
    "                         endpoint_name=endpoint_name, # define a unqie endpoint name; if ommited, Sagemaker will generate it based on used container\n",
    "                         tags=[{\"Key\":\"image\", \"Value\":f\"{container_serving}:{tag}\"}], \n",
    "                         wait=False\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scores': [0.07065121829509735, 0.0627947673201561, 0.057897597551345825, 0.057310961186885834, 0.05586083233356476, 0.05566409230232239, 0.05456484854221344, 0.05448320880532265, 0.054418615996837616, 0.05378342047333717, 0.052324000746011734, 0.051990900188684464, 0.051864221692085266, 0.05182945355772972, 0.05151841416954994, 0.05104076862335205], 'pred_classes': [50, 50, 25, 50, 50, 50, 50, 25, 50, 50, 50, 50, 50, 50, 50, 50], 'pred_boxes': [[359.2482604980469, 218.38162231445312, 389.8966064453125, 233.11915588378906], [385.6258239746094, 175.5543212890625, 419.8941955566406, 188.70645141601562], [411.733154296875, 173.13824462890625, 441.656494140625, 189.1190643310547], [368.893310546875, 203.00997924804688, 424.86834716796875, 231.60105895996094], [199.7201385498047, 305.2264709472656, 227.4170684814453, 319.90057373046875], [363.3564758300781, 210.84730529785156, 392.70379638671875, 227.9643096923828], [349.94091796875, 215.8382568359375, 404.67529296875, 247.44932556152344], [401.76544189453125, 368.2792053222656, 450.66845703125, 400.3157653808594], [346.5144348144531, 203.79049682617188, 403.00482177734375, 237.49380493164062], [398.78662109375, 302.2523193359375, 427.8790588378906, 317.1368103027344], [373.2522888183594, 220.45997619628906, 408.3104248046875, 237.6136016845703], [397.7847900390625, 305.9159240722656, 457.11798095703125, 337.2057189941406], [26.187366485595703, 346.49169921875, 58.8211669921875, 365.4715270996094], [389.3204650878906, 318.9445495605469, 417.62689208984375, 334.2420654296875], [365.2088928222656, 172.53475952148438, 433.5379638671875, 202.74020385742188], [372.3963317871094, 178.42881774902344, 407.23779296875, 193.1680450439453]]}\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client('sagemaker-runtime')\n",
    "accept_type = \"json\"\n",
    "content_type = 'image/jpeg'\n",
    "headers = {'content-type': content_type}\n",
    "payload = open('coco_sample.jpg', 'rb')\n",
    "\n",
    "client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=payload,\n",
    "    ContentType=content_type,\n",
    "    Accept = accept_type\n",
    ")\n",
    "\n",
    "if accept_type==\"json\":\n",
    "    predictions = json.loads(response.content)\n",
    "elif accept_type==\"detectron2\":\n",
    "    predictions = pickle.loads(response.content)\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
