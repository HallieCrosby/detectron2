{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from time import gmtime, strftime\n",
    "\n",
    "sess = sagemaker.Session() # can use LocalSession() to run container locally\n",
    "\n",
    "bucket = sess.default_bucket()\n",
    "region = \"us-east-2\"\n",
    "prefix_input = 'detectron2-input'\n",
    "prefix_output = 'detectron2-ouput'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'detectron2' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/facebookresearch/detectron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create stage directory: /home/ec2-user/SageMaker/coco-2017-2020-03-31-18-56-41\n",
      "--2020-03-31 18:56:41--  http://images.cocodataset.org/zips/train2017.zip\n",
      "Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.184.211\n",
      "Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.184.211|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 19336861798 (18G) [application/zip]\n",
      "Saving to: ‘/home/ec2-user/SageMaker/coco-2017-2020-03-31-18-56-41/train2017.zip’\n",
      "\n",
      "/home/ec2-user/Sage 100%[===================>]  18.01G  36.3MB/s    in 9m 46s  \n",
      "\n",
      "2020-03-31 19:06:27 (31.5 MB/s) - ‘/home/ec2-user/SageMaker/coco-2017-2020-03-31-18-56-41/train2017.zip’ saved [19336861798/19336861798]\n",
      "\n",
      "./upload_coco2017_to_s3.sh: line 19: zips/train2017.zip: No such file or directory\n",
      "Extracting /home/ec2-user/SageMaker/coco-2017-2020-03-31-18-56-41/train2017.zip\n",
      "===================================================================================================================================================================================="
     ]
    }
   ],
   "source": [
    "! ./upload_coco2017_to_s3.sh \"sagemaker-us-east-2-553020858742\" \"detectron2/datasets/coco\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/detectron2-sagemaker/detectron2/datasets/coco/annotations/person_keypoints_val2017_100.json\n",
      "file person_keypoints_val2017_100.json has been uploaded to S3\n",
      "/home/ec2-user/SageMaker/detectron2-sagemaker/detectron2/datasets/coco/annotations/instances_minival2014_100.json\n",
      "file instances_minival2014_100.json has been uploaded to S3\n",
      "/home/ec2-user/SageMaker/detectron2-sagemaker/detectron2/datasets/coco/annotations/person_keypoints_minival2014_100.json\n",
      "file person_keypoints_minival2014_100.json has been uploaded to S3\n",
      "/home/ec2-user/SageMaker/detectron2-sagemaker/detectron2/datasets/coco/annotations/instances_val2017_100.json\n",
      "file instances_val2017_100.json has been uploaded to S3\n"
     ]
    }
   ],
   "source": [
    "# TODO: delete\n",
    "# upload directory with COCO dataset to S3 location\n",
    "\n",
    "import os\n",
    "import boto3\n",
    "\n",
    "s3_resource = boto3.resource(\"s3\", region_name=\"us-east-2\")\n",
    "root_path = os.getcwd()\n",
    "data_path = os.path.join(root_path, \"detectron2/datasets/coco\")\n",
    "\n",
    "\n",
    "\n",
    "for path, subdirs, files in os.walk(data_path):\n",
    "    directory_name = path.replace(root_path+\"/\",\"\")\n",
    "    for file in files:\n",
    "        print(os.path.join(root_path, directory_name, file))\n",
    "        s3_resource.Bucket(bucket).upload_file(os.path.join(root_path, directory_name, file), directory_name+'/'+file)\n",
    "        print(f\"file {file} has been uploaded to S3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-2-553020858742/detectron2/datasets/coco/train'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"s3://{bucket}/detectron2/datasets/coco/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m#!/bin/bash -e\u001b[39;49;00m\n",
      "\u001b[37m# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved\u001b[39;49;00m\n",
      "\n",
      "\u001b[37m# Download some files needed for running tests.\u001b[39;49;00m\n",
      "\n",
      "\u001b[36mcd\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33m${\u001b[39;49;00m\u001b[31m0\u001b[39;49;00m%/*\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "\n",
      "\u001b[31mBASE\u001b[39;49;00m=https://dl.fbaipublicfiles.com/detectron2\n",
      "mkdir -p coco/annotations\n",
      "\n",
      "\u001b[34mfor\u001b[39;49;00m anno in instances_val2017_100 \u001b[33m\\\u001b[39;49;00m\n",
      "  person_keypoints_val2017_100 \u001b[33m\\\u001b[39;49;00m\n",
      "  instances_minival2014_100 \u001b[33m\\\u001b[39;49;00m\n",
      "  person_keypoints_minival2014_100; \u001b[34mdo\u001b[39;49;00m\n",
      "\n",
      "  \u001b[31mdest\u001b[39;49;00m=coco/annotations/\u001b[31m$anno\u001b[39;49;00m.json\n",
      "  [[ -s \u001b[31m$dest\u001b[39;49;00m ]] && {\n",
      "    \u001b[36mecho\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[31m$dest\u001b[39;49;00m\u001b[33m exists. Skipping ...\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "  } || {\n",
      "    wget \u001b[31m$BASE\u001b[39;49;00m/annotations/coco/\u001b[31m$anno\u001b[39;49;00m.json -O \u001b[31m$dest\u001b[39;49;00m\n",
      "  }\n",
      "\u001b[34mdone\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize ./detectron2/datasets/prepare_for_tests.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-07 12:56:53 Starting - Starting the training job...\n",
      "2020-04-07 12:56:54 Starting - Launching requested ML instances...\n",
      "2020-04-07 12:57:51 Starting - Preparing the instances for training......\n",
      "2020-04-07 12:58:44 Downloading - Downloading input data...\n",
      "2020-04-07 12:58:56 Training - Downloading the training image..............\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-04-07 13:01:34,752 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-04-07 13:01:34,778 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-04-07 13:01:35,432 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-04-07 13:01:35,436 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-04-07 13:01:35,436 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-04-07 13:01:35,437 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-04-07 13:01:35,437 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /tmp/tmp5yitp7h2/module_dir\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: default-user-module-name\n",
      "  Building wheel for default-user-module-name (setup.py): started\n",
      "  Building wheel for default-user-module-name (setup.py): finished with status 'done'\n",
      "  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=8946 sha256=b4c4f7fe28c5c730d53fe3006933f830e3d1e17d4476c4aca7bd4b623847d94d\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-kz5l0ozy/wheels/6b/41/17/da67595cb4f015f36048e46287737568f78fea1eb76a3198e4\u001b[0m\n",
      "\u001b[34mSuccessfully built default-user-module-name\u001b[0m\n",
      "\u001b[34mInstalling collected packages: default-user-module-name\u001b[0m\n",
      "\u001b[34mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
      "\u001b[34m2020-04-07 13:01:37,846 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"val\": \"/opt/ml/input/data/val\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"num_classes\": 2,\n",
      "        \"num_epochs\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"val\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"d2-sm-base-2020-04-07-12-56-53-332\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"/opt/ml/code\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"num_classes\":2,\"num_epochs\":1}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"val\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\",\"val\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=/opt/ml/code\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"val\":\"/opt/ml/input/data/val\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"num_classes\":2,\"num_epochs\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"val\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"d2-sm-base-2020-04-07-12-56-53-332\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--num_classes\",\"2\",\"--num_epochs\",\"1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VAL=/opt/ml/input/data/val\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_CLASSES=2\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_EPOCHS=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python train.py --num_classes 2 --num_epochs 1\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mCollecting numpy\n",
      "  Downloading numpy-1.18.2-cp36-cp36m-manylinux1_x86_64.whl (20.2 MB)\u001b[0m\n",
      "\n",
      "2020-04-07 13:01:33 Training - Training image download completed. Training in progress.\u001b[34mInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.16.4\n",
      "    Uninstalling numpy-1.16.4:\n",
      "      Successfully uninstalled numpy-1.16.4\u001b[0m\n",
      "\u001b[34mSuccessfully installed numpy-1.18.2\u001b[0m\n",
      "\u001b[34mCollecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
      "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-ez09uxtp\u001b[0m\n",
      "\u001b[34mRequirement already satisfied (use --upgrade to upgrade): pycocotools==2.0 from git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI in /opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools>=18.0 in /opt/conda/lib/python3.6/site-packages (from pycocotools==2.0) (46.1.3.post20200330)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cython>=0.27.3 in /opt/conda/lib/python3.6/site-packages (from pycocotools==2.0) (0.29.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.6/site-packages (from pycocotools==2.0) (3.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.11 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.18.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.4.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools==2.0) (1.14.0)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: pycocotools\n",
      "  Building wheel for pycocotools (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for pycocotools (setup.py): finished with status 'done'\n",
      "  Created wheel for pycocotools: filename=pycocotools-2.0-cp36-cp36m-linux_x86_64.whl size=288496 sha256=2616f365a34f0b4bbaf776ae67a424469c0010173727fa1d72838f6236fb406c\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ncr0s50r/wheels/25/c1/63/8bee2969883497d2785c9bdbe4e89cae5efc59521553d528bf\u001b[0m\n",
      "\u001b[34mSuccessfully built pycocotools\u001b[0m\n",
      "\u001b[34m#033[32m[04/07 13:01:57 d2.engine.defaults]: #033[0mModel:\u001b[0m\n",
      "\u001b[34mGeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\u001b[0m\n",
      "\u001b[34m)\u001b[0m\n",
      "\u001b[34m#033[32m[04/07 13:01:59 d2.data.build]: #033[0mRemoved 0 images with no usable annotations. 61 images left.\u001b[0m\n",
      "\u001b[34m#033[32m[04/07 13:01:59 d2.data.build]: #033[0mDistribution of instances among all 1 categories:\u001b[0m\n",
      "\u001b[34m#033[36m|  category  | #instances   |\u001b[0m\n",
      "\u001b[34m|:----------:|:-------------|\u001b[0m\n",
      "\u001b[34m|  balloon   | 255          |\u001b[0m\n",
      "\u001b[34m|            |              |#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[04/07 13:01:59 d2.data.common]: #033[0mSerializing 61 elements to byte tensors and concatenating them all ...\u001b[0m\n",
      "\u001b[34m#033[32m[04/07 13:01:59 d2.data.common]: #033[0mSerialized dataset takes 0.17 MiB\u001b[0m\n",
      "\u001b[34m#033[32m[04/07 13:01:59 d2.data.detection_utils]: #033[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\u001b[0m\n",
      "\u001b[34m#033[32m[04/07 13:01:59 d2.data.build]: #033[0mUsing training sampler TrainingSampler\u001b[0m\n",
      "\u001b[34m#033[32m[04/07 13:02:08 d2.engine.train_loop]: #033[0mStarting training from iteration 0\u001b[0m\n",
      "\u001b[34m#033[4m#033[5m#033[31mERROR#033[0m #033[32m[04/07 13:02:12 d2.engine.train_loop]: #033[0mException during training:\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/detectron2/engine/train_loop.py\", line 132, in train\n",
      "    self.run_step()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/detectron2/engine/train_loop.py\", line 215, in run_step\n",
      "    loss_dict = self.model(data)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 543, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/detectron2/modeling/meta_arch/rcnn.py\", line 124, in forward\n",
      "    proposals, proposal_losses = self.proposal_generator(images, features, gt_instances)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 543, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/detectron2/modeling/proposal_generator/rpn.py\", line 182, in forward\n",
      "    self.training,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/detectron2/modeling/proposal_generator/rpn_outputs.py\", line 148, in find_top_rpn_proposals\n",
      "    keep = batched_nms(boxes.tensor, scores_per_img, lvl, nms_thresh)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/detectron2/layers/nms.py\", line 17, in batched_nms\n",
      "    return box_ops.batched_nms(boxes, scores, idxs, iou_threshold)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torchvision/ops/boxes.py\", line 76, in batched_nms\n",
      "    keep = nms(boxes_for_nms, scores, iou_threshold)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torchvision/ops/boxes.py\", line 36, in nms\n",
      "    return torch.ops.torchvision.nms(boxes, scores, iou_threshold)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/_ops.py\", line 61, in __getattr__\n",
      "    op = torch._C._jit_get_operation(qualified_op_name)\u001b[0m\n",
      "\u001b[34mRuntimeError: No such operator torchvision::nms\u001b[0m\n",
      "\u001b[34m#033[32m[04/07 13:02:12 d2.engine.hooks]: #033[0mTotal training time: 0:00:03 (0:00:00 on hooks)\u001b[0m\n",
      "\u001b[34m2020-04-07 13:02:12,499 sagemaker-containers ERROR    ExecuteUserScriptError:\u001b[0m\n",
      "\u001b[34mCommand \"/opt/conda/bin/python train.py --num_classes 2 --num_epochs 1\"\n",
      "  Running command git clone -q https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-ez09uxtp\u001b[0m\n",
      "\u001b[34m#015model_final_f10217.pkl: 0.00B [00:00, ?B/s]#015model_final_f10217.pkl:   0%|          | 8.19k/178M [00:00<4:08:17, 11.9kB/s]#015model_final_f10217.pkl:   0%|          | 106k/178M [00:00<2:55:14, 16.9kB/s] #015model_final_f10217.pkl:   0%|          | 524k/178M [00:01<2:02:42, 24.1kB/s]#015model_final_f10217.pkl:   1%|          | 2.17M/178M [00:01<1:25:10, 34.4kB/s]#015model_final_f10217.pkl:   3%|â         | 6.04M/178M [00:01<58:20, 49.1kB/s]  #015model_final_f10217.pkl:   5%|â         | 9.63M/178M [00:01<40:00, 70.1kB/s]#015model_final_f10217.pkl:   6%|â         | 11.4M/178M [00:01<27:46, 99.9kB/s]#015model_final_f10217.pkl:   8%|â         | 14.7M/178M [00:01<19:05, 142kB/s] #015model_final_f10217.pkl:   9%|â         | 16.1M/178M [00:01<13:18, 203kB/s]#015model_final_f10217.pkl:   9%|â         | 16.8M/178M [00:01<09:24, 286kB/s]#015model_final_f10217.pkl:  11%|â         | 18.9M/178M [00:01<06:31, 405kB/s]#015model_final_f10217.pkl:  12%|ââ        | 21.0M/178M [00:02<04:33, 574kB/s]#015model_final_f10217.pkl:  13%|ââ        | 23.8M/178M [00:02<03:09, 813kB/s]#015model_final_f10217.pkl:  15%|ââ        | 25.9M/178M [00:02<02:12, 1.14MB/s]#015model_final_f10217.pkl:  16%|ââ        | 28.9M/178M [00:02<01:33, 1.60MB/s]#015model_final_f10217.pkl:  18%|ââ        | 31.4M/178M [00:02<01:05, 2.23MB/s]#015model_final_f10217.pkl:  19%|ââ        | 33.6M/178M [00:02<00:47, 3.04MB/s]#015model_final_f10217.pkl:  20%|ââ        | 36.1M/178M [00:02<00:34, 4.11MB/s]#015model_final_f10217.pkl:  22%|âââ       | 38.4M/178M [00:02<00:25, 5.46MB/s]#015model_final_f10217.pkl:  23%|âââ       | 41.3M/178M [00:02<00:18, 7.21MB/s]#015model_final_f10217.pkl:  25%|âââ       | 44.0M/178M [00:03<00:14, 9.11MB/s]#015model_final_f10217.pkl:  26%|âââ       | 46.5M/178M [00:03<00:11, 11.1MB/s]#015model_final_f10217.pkl:  28%|âââ       | 49.3M/178M [00:03<00:09, 13.4MB/s]#015model_final_f10217.pkl:  29%|âââ       | 51.9M/178M [00:03<00:08, 15.5MB/s]#015model_final_f10217.pkl:  31%|âââ       | 54.5M/178M [00:03<00:07, 17.4MB/s]#015model_final_f10217.pkl:  32%|ââââ      | 57.2M/178M [00:03<00:06, 19.5MB/s]#015model_final_f10217.pkl:  34%|ââââ      | 59.6M/178M [00:03<00:06, 19.4MB/s]#015model_final_f10217.pkl:  35%|ââââ      | 61.7M/178M [00:03<00:06, 18.7MB/s]#015model_final_f10217.pkl:  37%|ââââ      | 65.3M/178M [00:03<00:05, 21.7MB/s]#015model_final_f10217.pkl:  38%|ââââ      | 67.5M/178M [00:04<00:05, 21.0MB/s]#015model_final_f10217.pkl:  39%|ââââ      | 69.8M/178M [00:04<00:04, 21.7MB/s]#015model_final_f10217.pkl:  41%|ââââ      | 72.5M/178M [00:04<00:04, 23.0MB/s]#015model_final_f10217.pkl:  42%|âââââ     | 74.8M/178M [00:04<00:04, 23.1MB/s]#015model_final_f10217.pkl:  43%|âââââ     | 77.3M/178M [00:04<00:04, 23.0MB/s]#015model_final_f10217.pkl:  45%|âââââ     | 80.3M/178M [00:04<00:03, 24.6MB/s]#015model_final_f10217.pkl:  47%|âââââ     | 83.1M/178M [00:04<00:03, 24.9MB/s]#015model_final_f10217.pkl:  48%|âââââ     | 85.4M/178M [00:04<00:03, 23.2MB/s]#015model_final_f10217.pkl:  50%|âââââ     | 88.4M/178M [00:04<00:03, 24.9MB/s]#015model_final_f10217.pkl:  51%|ââââââ    | 91.2M/178M [00:04<00:03, 24.4MB/s]#015model_final_f10217.pkl:  53%|ââââââ    | 93.9M/178M [00:05<00:03, 24.6MB/s]#015model_final_f10217.pkl:  54%|ââââââ    | 96.9M/178M [00:05<00:03, 25.9MB/s]#015model_final_f10217.pkl:  56%|ââââââ    | 99.4M/178M [00:05<00:03, 25.0MB/s]#015model_final_f10217.pkl:  57%|ââââââ    | 102M/178M [00:05<00:03, 23.8MB/s] #015model_final_f10217.pkl:  59%|ââââââ    | 105M/178M [00:05<00:02, 25.4MB/s]#015model_final_f10217.pkl:  60%|ââââââ    | 107M/178M [00:05<00:02, 25.0MB/s]#015model_final_f10217.pkl:  62%|âââââââ   | 110M/178M [00:05<00:02, 24.9MB/s]#015model_final_f10217.pkl:  63%|âââââââ   | 113M/178M [00:05<00:02, 25.7MB/s]#015model_final_f10217.pkl:  65%|âââââââ   | 115M/178M [00:05<00:02, 25.7MB/s]#015model_final_f10217.pkl:  66%|âââââââ   | 118M/178M [00:06<00:02, 24.0MB/s]#015model_final_f10217.pkl:  68%|âââââââ   | 120M/178M [00:06<00:02, 24.3MB/s]#015model_final_f10217.pkl:  69%|âââââââ   | 122M/178M [00:06<00:02, 23.5MB/s]#015model_final_f10217.pkl:  70%|âââââââ   | 125M/178M [00:06<00:02, 23.2MB/s]#015model_final_f10217.pkl:  72%|ââââââââ  | 128M/178M [00:06<00:02, 24.4MB/s]#015model_final_f10217.pkl:  73%|ââââââââ  | 131M/178M [00:06<00:01, 25.3MB/s]#015model_final_f10217.pkl:  75%|ââââââââ  | 133M/178M [00:06<00:01, 25.0MB/s]#015model_final_f10217.pkl:  76%|ââââââââ  | 135M/178M [00:06<00:01, 24.1MB/s]#015model_final_f10217.pkl:  78%|ââââââââ  | 138M/178M [00:06<00:01, 24.4MB/s]#015model_final_f10217.pkl:  79%|ââââââââ  | 141M/178M [00:06<00:01, 25.5MB/s]#015model_final_f10217.pkl:  81%|ââââââââ  | 144M/178M [00:07<00:01, 25.3MB/s]#015model_final_f10217.pkl:  82%|âââââââââ | 146M/178M [00:07<00:01, 24.5MB/s]#015model_final_f10217.pkl:  83%|âââââââââ | 148M/178M [00:07<00:01, 19.5MB/s]#015model_final_f10217.pkl:  84%|âââââââââ | 150M/178M [00:07<00:01, 19.2MB/s]#015model_final_f10217.pkl:  86%|âââââââââ | 153M/178M [00:07<00:01, 20.4MB/s]#015model_final_f10217.pkl:  87%|âââââââââ | 155M/178M [00:07<00:01, 21.0MB/s]#015model_final_f10217.pkl:  89%|âââââââââ | 159M/178M [00:07<00:00, 23.0MB/s]#015model_final_f10217.pkl:  90%|âââââââââ | 161M/178M [00:07<00:00, 22.3MB/s]#015model_final_f10217.pkl:  92%|ââââââââââ| 163M/178M [00:07<00:00, 22.9MB/s]#015model_final_f10217.pkl:  93%|ââââââââââ| 166M/178M [00:08<00:00, 21.8MB/s]#015model_final_f10217.pkl:  95%|ââââââââââ| 169M/178M [00:08<00:00, 23.9MB/s]#015model_final_f10217.pkl:  97%|ââââââââââ| 172M/178M [00:08<00:00, 23.8MB/s]#015model_final_f10217.pkl:  98%|ââââââââââ| 174M/178M [00:08<00:00, 20.7MB/s]#015model_final_f10217.pkl: 178MB [00:08, 20.8MB/s]                           \u001b[0m\n",
      "\u001b[34m'roi_heads.box_predictor.cls_score.weight' has shape (81, 1024) in the checkpoint but (2, 1024) in the model! Skipped.\u001b[0m\n",
      "\u001b[34m'roi_heads.box_predictor.cls_score.bias' has shape (81,) in the checkpoint but (2,) in the model! Skipped.\u001b[0m\n",
      "\u001b[34m'roi_heads.box_predictor.bbox_pred.weight' has shape (320, 1024) in the checkpoint but (4, 1024) in the model! Skipped.\u001b[0m\n",
      "\u001b[34m'roi_heads.box_predictor.bbox_pred.bias' has shape (320,) in the checkpoint but (4,) in the model! Skipped.\u001b[0m\n",
      "\u001b[34m'roi_heads.mask_head.predictor.weight' has shape (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! Skipped.\u001b[0m\n",
      "\u001b[34m'roi_heads.mask_head.predictor.bias' has shape (80,) in the checkpoint but (1,) in the model! Skipped.\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"train.py\", line 105, in <module>\n",
      "    train()\n",
      "  File \"train.py\", line 52, in train\n",
      "    trainer.train()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/detectron2/engine/defaults.py\", line 380, in train\n",
      "    super().train(self.start_iter, self.max_iter)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/detectron2/engine/train_loop.py\", line 132, in train\n",
      "    self.run_step()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/detectron2/engine/train_loop.py\", line 215, in run_step\n",
      "    loss_dict = self.model(data)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 543, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/detectron2/modeling/meta_arch/rcnn.py\", line 124, in forward\n",
      "    proposals, proposal_losses = self.proposal_generator(images, features, gt_instances)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 543, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/detectron2/modeling/proposal_generator/rpn.py\", line 182, in forward\n",
      "    self.training,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/detectron2/modeling/proposal_generator/rpn_outputs.py\", line 148, in find_top_rpn_proposals\n",
      "    keep = batched_nms(boxes.tensor, scores_per_img, lvl, nms_thresh)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/detectron2/layers/nms.py\", line 17, in batched_nms\n",
      "    return box_ops.batched_nms(boxes, scores, idxs, iou_threshold)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torchvision/ops/boxes.py\", line 76, in batched_nms\n",
      "    keep = nms(boxes_for_nms, scores, iou_threshold)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torchvision/ops/boxes.py\", line 36, in nms\n",
      "    return torch.ops.torchvision.nms(boxes, scores, iou_threshold)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/_ops.py\", line 61, in __getattr__\n",
      "    op = torch._C._jit_get_operation(qualified_op_name)\u001b[0m\n",
      "\u001b[34mRuntimeError: No such operator torchvision::nms\u001b[0m\n",
      "\n",
      "2020-04-07 13:02:20 Uploading - Uploading generated training model\n",
      "2020-04-07 13:02:20 Failed - Training job failed\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job d2-sm-base-2020-04-07-12-56-53-332: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nCommand \"/opt/conda/bin/python train.py --num_classes 2 --num_epochs 1\"\n  Running command git clone -q https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-ez09uxtp\n\rmodel_final_f10217.pkl: 0.00B [00:00, ?B/s]\rmodel_final_f10217.pkl:   0%|          | 8.19k/178M [00:00<4:08:17, 11.9kB/s]\rmodel_final_f10217.pkl:   0%|          | 106k/178M [00:00<2:55:14, 16.9kB/s] \rmodel_final_f10217.pkl:   0%|          | 524k/178M [00:01<2:02:42, 24.1kB/s]\rmodel_final_f10217.pkl:   1%|          | 2.17M/178M [00:01<1:25:10, 34.4kB/s]\rmodel_final_f10217.pkl:   3%|â         | 6.04M/178M [00:01<58:20, 49.1kB/s]  \rmodel_final_f10217.pkl:   5%|â         | 9.63M/178M [00:01<40:00, 70.1kB/s]\rmodel_final_f10217.pkl:   6%|â         | 11.4M/178M [00:01<27:46, 99.9kB/s]\rmodel_final_f10217.pkl:   8%|â         | 14.7M/178M [00:01<19:05, 142kB/s] \rmodel_final_f10217.pkl:   9%|â         | 16.1M/178M [00:01<13:18, 203kB/s]\rmodel_final_f10217.pkl:   9%|â         | 16.8M/178M [00:01<09",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6c51b49cce08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m d2.fit({'train':\"s3://sagemaker-us-east-2-553020858742/balloon/train\",\n\u001b[0;32m---> 17\u001b[0;31m         'val':\"s3://sagemaker-us-east-2-553020858742/balloon/val\"}) \n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   1061\u001b[0m         \u001b[0;31m# If logs are requested, call logs_for_jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   3021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3022\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3023\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TrainingJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3024\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3025\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   2615\u001b[0m                 ),\n\u001b[1;32m   2616\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2617\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2618\u001b[0m             )\n\u001b[1;32m   2619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job d2-sm-base-2020-04-07-12-56-53-332: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nCommand \"/opt/conda/bin/python train.py --num_classes 2 --num_epochs 1\"\n  Running command git clone -q https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-ez09uxtp\n\rmodel_final_f10217.pkl: 0.00B [00:00, ?B/s]\rmodel_final_f10217.pkl:   0%|          | 8.19k/178M [00:00<4:08:17, 11.9kB/s]\rmodel_final_f10217.pkl:   0%|          | 106k/178M [00:00<2:55:14, 16.9kB/s] \rmodel_final_f10217.pkl:   0%|          | 524k/178M [00:01<2:02:42, 24.1kB/s]\rmodel_final_f10217.pkl:   1%|          | 2.17M/178M [00:01<1:25:10, 34.4kB/s]\rmodel_final_f10217.pkl:   3%|â         | 6.04M/178M [00:01<58:20, 49.1kB/s]  \rmodel_final_f10217.pkl:   5%|â         | 9.63M/178M [00:01<40:00, 70.1kB/s]\rmodel_final_f10217.pkl:   6%|â         | 11.4M/178M [00:01<27:46, 99.9kB/s]\rmodel_final_f10217.pkl:   8%|â         | 14.7M/178M [00:01<19:05, 142kB/s] \rmodel_final_f10217.pkl:   9%|â         | 16.1M/178M [00:01<13:18, 203kB/s]\rmodel_final_f10217.pkl:   9%|â         | 16.8M/178M [00:01<09"
     ]
    }
   ],
   "source": [
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = \"us-east-2\"\n",
    "container = \"d2-sm-base\"\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(account, region, container)\n",
    "\n",
    "d2 = sagemaker.estimator.Estimator(image,\n",
    "                                   role=role,\n",
    "                                   train_instance_count=1, \n",
    "                                   train_instance_type='ml.p3.2xlarge',\n",
    "                                   train_volume_size=100,\n",
    "                                   output_path=\"s3://{}/{}\".format(sess.default_bucket(), prefix_output),\n",
    "                                   sagemaker_session=sess)\n",
    "\n",
    "d2.set_hyperparameters(num_epochs = 1, num_classes = 2, )\n",
    "\n",
    "d2.fit({'train':\"s3://sagemaker-us-east-2-553020858742/balloon/train\",\n",
    "        'val':\"s3://sagemaker-us-east-2-553020858742/balloon/val\"}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO fix the issue with hostnames: https://github.com/aws/sagemaker-pytorch-container/issues/143\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
