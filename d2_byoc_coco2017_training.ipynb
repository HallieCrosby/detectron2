{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from time import gmtime, strftime\n",
    "\n",
    "sess = sagemaker.LocalSession() # can use LocalSession() to run container locally\n",
    "\n",
    "bucket = sess.default_bucket()\n",
    "region = \"us-east-2\"\n",
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "prefix_input = 'detectron2-input'\n",
    "prefix_output = 'detectron2-ouput'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./upload_coco2017_to_s3.sh <your_bucket> <your_s3_path>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push Docker image to registry\n",
    "\n",
    "For this training, we'll extend [Sagemaker PyTorch Container](https://docs.aws.amazon.com/deep-learning-containers/latest/devguide/deep-learning-containers-images.html) with Detectron2 dependencies (using official [D2 Dockerfile](https://github.com/facebookresearch/detectron2/blob/master/docker/Dockerfile)) as baseline. See Dockerfile below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m# Build an image of Detectron2 that can do \u001b[39;49;00m\n",
      "\u001b[37m# distributing training and inference in Amazon Sagemaker\u001b[39;49;00m\n",
      "\n",
      "\u001b[37m# using Sagemaker PyTorch container as base image\u001b[39;49;00m\n",
      "\u001b[34mFROM\u001b[39;49;00m\u001b[33m 763104351884.dkr.ecr.us-east-2.amazonaws.com/pytorch-training:1.4.0-gpu-py36-cu101-ubuntu16.04\u001b[39;49;00m\n",
      "LABEL \u001b[31mauthor\u001b[39;49;00m=\u001b[33m\"vadimd@amazon.com\"\u001b[39;49;00m\n",
      "\n",
      "\u001b[37m############# Installing latest builds ############\u001b[39;49;00m\n",
      "\n",
      "\u001b[37m# This is to fix issue: https://github.com/pytorch/vision/issues/1489\u001b[39;49;00m\n",
      "\u001b[34mRUN\u001b[39;49;00m pip install --upgrade --force-reinstall torch torchvision cython\n",
      "\n",
      "\u001b[37m############# D2 section ##############\u001b[39;49;00m\n",
      "\n",
      "\u001b[37m# installing dependecies for D2 https://github.com/facebookresearch/detectron2/blob/master/docker/Dockerfile\u001b[39;49;00m\n",
      "\u001b[34mRUN\u001b[39;49;00m pip install \u001b[33m'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\u001b[39;49;00m\n",
      "\u001b[34mRUN\u001b[39;49;00m pip install \u001b[33m'git+https://github.com/facebookresearch/fvcore'\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mENV\u001b[39;49;00m\u001b[33m FORCE_CUDA=\"1\"\u001b[39;49;00m\n",
      "\u001b[37m# Build D2 only for Volta architecture - V100 chips (ml.p3 AWS instances)\u001b[39;49;00m\n",
      "\u001b[34mENV\u001b[39;49;00m\u001b[33m TORCH_CUDA_ARCH_LIST=\"Volta\" \u001b[39;49;00m\n",
      "\n",
      "\u001b[37m# Build D2 from latest sources\u001b[39;49;00m\n",
      "\u001b[34mRUN\u001b[39;49;00m pip install \u001b[33m'git+https://github.com/facebookresearch/detectron2.git'\u001b[39;49;00m\n",
      "\n",
      "\u001b[37m# Set a fixed model cache directory. Detectron2 requirement\u001b[39;49;00m\n",
      "\u001b[34mENV\u001b[39;49;00m\u001b[33m FVCORE_CACHE=\"/tmp\"\u001b[39;49;00m\n",
      "\u001b[37m# set location of training datasetm, Sagemaker containers copy all data from S3 to /opt/ml/input/data/{channels}\u001b[39;49;00m\n",
      "\u001b[34mENV\u001b[39;49;00m\u001b[33m DETECTRON2_DATASETS=\"/opt/ml/input/data/training\"\u001b[39;49;00m\n",
      "\n",
      "\u001b[37m############# SageMaker section ##############\u001b[39;49;00m\n",
      "\n",
      "COPY container_training /opt/ml/code\n",
      "\u001b[34mWORKDIR\u001b[39;49;00m\u001b[33m /opt/ml/code\u001b[39;49;00m\n",
      "\n",
      "\u001b[37m# cloning D2 to code dir as we need access to default congigs\u001b[39;49;00m\n",
      "\u001b[34mRUN\u001b[39;49;00m git clone \u001b[33m'https://github.com/facebookresearch/detectron2.git'\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mENV\u001b[39;49;00m\u001b[33m SAGEMAKER_SUBMIT_DIRECTORY /opt/ml/code\u001b[39;49;00m\n",
      "\u001b[34mENV\u001b[39;49;00m\u001b[33m SAGEMAKER_PROGRAM train_coco.py\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mWORKDIR\u001b[39;49;00m\u001b[33m /\u001b[39;49;00m\n",
      "\n",
      "\u001b[37m# Starts PyTorch distributed framework\u001b[39;49;00m\n",
      "\u001b[34mENTRYPOINT\u001b[39;49;00m\u001b[33m [\"bash\", \"-m\", \"start_with_right_hostname.sh\"]\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll need to build container from this Dockerfile and push it to Amazon Elastic Container Registry using `build_and_push.sh` script. But you'll need to loging to Sagemaker ECR and your private ECR first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n"
     ]
    }
   ],
   "source": [
    "# loging to Sagemaker ECR with Deep Learning Containers\n",
    "!aws ecr get-login-password --region us-east-2 | docker login --username AWS --password-stdin 763104351884.dkr.ecr.us-east-2.amazonaws.com\n",
    "# loging to your private ECR\n",
    "!aws ecr get-login-password --region us-east-2 | docker login --username AWS --password-stdin 553020858742.dkr.ecr.us-east-2.amazonaws.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can ready to push your D2 container to private ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./build_and_push.sh d2-sm-coco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define algorithm metrics which Sagemaker will scrap, persist, and render in training job console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = \"d2-sm-coco\" # your container name\n",
    "tag = \"debug\"\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/{}:{}'.format(account, region, container, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions=[\n",
    "    {\n",
    "        \"Name\": \"total_loss\",\n",
    "        \"Regex\": \".*total_loss:\\s([0-9\\\\.]+)\\s*\"\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"loss_cls\",\n",
    "        \"Regex\": \".*loss_cls:\\s([0-9\\\\.]+)\\s*\"\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"loss_box_reg\",\n",
    "        \"Regex\": \".*loss_box_reg:\\s([0-9\\\\.]+)\\s*\"\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"loss_mask\",\n",
    "        \"Regex\": \".*loss_mask:\\s([0-9\\\\.]+)\\s*\"\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"loss_rpn_cls\",\n",
    "        \"Regex\": \".*loss_rpn_cls:\\s([0-9\\\\.]+)\\s*\"\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"loss_rpn_loc\",\n",
    "        \"Regex\": \".*loss_rpn_loc:\\s([0-9\\\\.]+)\\s*\"\n",
    "    }, \n",
    "    {\n",
    "        \"Name\": \"overall_training_speed\",\n",
    "        \"Regex\": \".*Overall training speed:\\s([0-9\\\\.]+)\\s*\"\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"lr\",  \n",
    "        \"Regex\": \".*lr:\\s([0-9\\\\.]+)\\s*\"\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"iter\",  \n",
    "        \"Regex\": \".*iter:\\s([0-9\\\\.]+)\\s*\"\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\"config-file\":\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml\", \n",
    "                   #\"local-config-file\" : \"config.yaml\", # if you'd like to supply custom config file, please it in container_training folder, and provide file name here\n",
    "                   \"resume\":\"True\", # whether to re-use weights from pre-trained model\n",
    "                   \"eval-only\":\"True\", # whether to perform only D2 model evaluation\n",
    "                  # opts are D2 model configuration as defined here: https://detectron2.readthedocs.io/modules/config.html#config-references\n",
    "                  # this is a way to override individual parameters in D2 configuration from Sagemaker API\n",
    "                   \"opts\": \"DATALOADER.NUM_WORKERS 8\"\n",
    "                   }\n",
    "\n",
    "    \n",
    "d2 = sagemaker.estimator.Estimator(image,\n",
    "                                   role=role,\n",
    "                                   train_instance_count=1, \n",
    "#                                   train_instance_type='ml.p3.16xlarge',\n",
    "                                   train_instance_type=\"local_gpu\", # use local_gpu for quick troubleshooting\n",
    "                                   train_volume_size=100,\n",
    "                                   output_path=\"s3://{}/{}\".format(sess.default_bucket(), prefix_output),\n",
    "                                   metric_definitions = metric_definitions,\n",
    "                                   hyperparameters = hyperparameters, \n",
    "                                   tags=[{\"Key\":\"Desc\", \"Value\":\"test Cristian config\"}],\n",
    "                                   sagemaker_session=sess)\n",
    "\n",
    "#d2.fit({'training':\"s3://coco2017-2a27f\"}, wait=False) \n",
    "d2.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with Spot Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_use_spot_instances = True\n",
    "train_max_run=21600\n",
    "train_max_wait = 30000 if train_use_spot_instances else None\n",
    "\n",
    "import uuid\n",
    "checkpoint_suffix = str(uuid.uuid4())[:8]\n",
    "checkpoint_s3_uri = 's3://{}/artifacts/mxnet-checkpoint-{}/'.format(bucket, checkpoint_suffix) if train_use_spot_instances else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = \"d2-sm-coco-custom\" # your container name\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(account, region, container)\n",
    "\n",
    "hyperparameters = {\"config-file\":\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml\", \n",
    "                   \"resume\":\"False\", # whether to re-use weights from pre-trained model\n",
    "                   \"eval-only\":\"False\", # whether to perform only D2 model evaluation\n",
    "                  # opts are D2 model configuration as defined here: https://detectron2.readthedocs.io/modules/config.html#config-references\n",
    "                  # this is a way to override default D2 configuration from Sagemaker API\n",
    "                  \"opts\": \"SOLVER.BASE_LR 0.00025 \\\n",
    "                           MODEL.ROI_HEADS.NUM_CLASSES 80 \\\n",
    "                           DATALOADER.NUM_WORKERS 4\"\n",
    "                  }\n",
    "\n",
    "d2 = sagemaker.estimator.Estimator(image,\n",
    "                                   role=role,\n",
    "                                   train_instance_count=2, \n",
    "                                   train_instance_type='ml.p3.16xlarge',\n",
    "#                                   train_instance_type=\"local_gpu\", # use local_gpu for quick troubleshooting\n",
    "                                   train_volume_size=100,\n",
    "                                   output_path=\"s3://{}/{}\".format(sess.default_bucket(), prefix_output),\n",
    "                                   metric_definitions = metric_definitions,\n",
    "                                   hyperparameters = hyperparameters, \n",
    "                                   tags=[{\"Key\":\"Desc\", \"Value\":\"spot training\"}],\n",
    "                                   sagemaker_session=sess,\n",
    "                                   train_use_spot_instances=train_use_spot_instances,\n",
    "                                   train_max_run=train_max_run,\n",
    "                                   train_max_wait=train_max_wait,\n",
    "                                   checkpoint_s3_uri=checkpoint_s3_uri)\n",
    "\n",
    "d2.fit({'training':\"s3://coco2017-2a27f\"}, wait=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
